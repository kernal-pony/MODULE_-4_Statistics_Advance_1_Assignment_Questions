{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOsGa62V5l1D"
      },
      "outputs": [],
      "source": [
        "# 1. Explain the properties of the F-distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Properties of the F-Distribution:\n",
        "\n",
        "1. **Shape**:\n",
        "   - The F-distribution is **right-skewed** and takes only **positive values** (i.e., \\( F>= 0)).\n",
        "\n",
        "2. **Degrees of Freedom**:\n",
        "   - It is defined by two sets of degrees of freedom:\n",
        "     - **Numerator degrees of freedom** ( df_1 ): Associated with the variance of the first sample.\n",
        "     - **Denominator degrees of freedom** ( df_2 ): Associated with the variance of the second sample.\n",
        "\n",
        "3. **Mean**:\n",
        "   - The mean of the F-distribution is given by:\n",
        "\n",
        "     Mean = \\frac{df_2}{df_2 - 2} ;for \\( df_2 > 2}\n",
        "     \\]\n",
        "\n",
        "4. **Variance**:\n",
        "   - The variance of the F-distribution is:\n",
        "\n",
        "{Variance = frac{2(df_2)^2 (df_1 + df_1 - 2)}{df_1 (df_2 - 2)^2 (df_2 - 4)\n",
        "(for df_2 > 4)\n",
        "\n",
        "\n",
        "5. **Asymptotic Behavior**:\n",
        "   - As \\( df_2  to infty), the F-distribution approaches a **normal distribution**.\n",
        "\n",
        "6. **Used in Hypothesis Testing**:\n",
        "   - Commonly used in **ANOVA (Analysis of Variance)**, **regression analysis**, and **variance comparison** tests.\n",
        "\n",
        "7. **Non-Negative**:\n",
        "   - The values of the F-distribution are always **positive** since it is derived from squared terms (variances).\n",
        "\n",
        "8. **Skewness**:\n",
        "   - The distribution is **right-skewed**, especially when degrees of freedom are small. As the degrees of freedom increase, the distribution becomes more symmetric.\n"
      ],
      "metadata": {
        "id": "PZf3Z6Q_5_do"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RR0zY57871pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
      ],
      "metadata": {
        "id": "rYZ-7iWh73eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **F-distribution** is used in the following statistical tests:\n",
        "\n",
        "1. **ANOVA (Analysis of Variance)**: Compares the means of three or more groups by comparing the variance between groups to the variance within groups.\n",
        "\n",
        "2. **F-test for Comparing Variances**: Compares the variances of two populations to check if they are significantly different.\n",
        "\n",
        "3. **Regression Analysis (F-test for Model Significance)**: Tests whether a regression model explains a significant amount of variance in the dependent variable.\n",
        "\n",
        "4. **MANOVA (Multivariate Analysis of Variance)**: Compares means of multiple dependent variables across groups.\n",
        "\n",
        "**Why F-distribution?**\n",
        "- It deals with the ratio of variances.\n",
        "- It is non-negative and right-skewed, making it suitable for variance-based tests."
      ],
      "metadata": {
        "id": "JqTb2SXP8feM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYREl_GH78vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?"
      ],
      "metadata": {
        "id": "a72Ur2hg8lHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key assumptions for conducting an **F-test** to compare the variances of two populations are:\n",
        "\n",
        "1. **Independence**: The two samples must be independent of each other.\n",
        "2. **Normality**: Both populations should follow a **normal distribution**.\n",
        "3. **Ratio of Variances**: The F-test compares the ratio of the variances from the two samples.\n",
        "\n",
        "These assumptions ensure the validity of the F-test for comparing variances."
      ],
      "metadata": {
        "id": "9t0_vg_28ldc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxHEWZhB9ik2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. What is the purpose of ANOVA, and how does it differ from a t-test?"
      ],
      "metadata": {
        "id": "w7m_MZr-9klU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Assumptions for F-test to Compare Variances\n",
        "\n",
        "| Assumption         | Description                                                              |\n",
        "|--------------------|--------------------------------------------------------------------------|\n",
        "| **Independence**    | The two samples must be **independent** of each other.                   |\n",
        "| **Normality**       | Both populations should follow a **normal distribution**.               |\n",
        "| **Ratio of Variances** | The F-test compares the **ratio of the variances** of the two samples. |\n",
        "\n",
        "\n",
        "Difference from a t-test:\n",
        "\n",
        "A t-test compares the means of two groups.\n",
        "ANOVA compares the means of three or more groups simultaneously and tests for overall differences, not just pairwise comparisons.\n"
      ],
      "metadata": {
        "id": "IsUmSmGl95hN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMcP6tx294L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups."
      ],
      "metadata": {
        "id": "7QEFURBE-H3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are the 2 main reasons to use one single ANOVA test instad of multiple t-test as :\n",
        "\n",
        "- Prevents Type I Errors: Multiple t-tests increase the risk of committing a Type I error (false positive) due to multiple comparisons. ANOVA controls this risk by testing all groups simultaneously.\n",
        "\n",
        "- Efficient: ANOVA tests if there is any significant difference between the means of more than two groups with a single test, whereas multiple t-tests require more tests and complex adjustments."
      ],
      "metadata": {
        "id": "hMrDSOtP-VrS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l78tDzU4-iRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?"
      ],
      "metadata": {
        "id": "daNY8W87-ivc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **ANOVA**, variance is partitioned into two components:\n",
        "\n",
        "1. **Between-group variance**: Measures the variability of **group means** around the **overall mean**. It reflects how different the groups are from each other.\n",
        "   \n",
        "2. **Within-group variance**: Measures the variability **within each group**. It reflects how much individual data points vary from their respective group means.\n",
        "\n",
        "### Contribution to F-statistic:\n",
        "The **F-statistic** is calculated as the ratio of **between-group variance** to **within-group variance**:\n",
        "\n",
        "F ={Between-group variance}}/{Within-group variance}\n",
        "\n",
        "\n",
        "- A **large F-statistic** suggests that the between-group variance is much larger than the within-group variance, indicating significant differences between groups.\n",
        "- A **small F-statistic** suggests that the within-group variance is large relative to the between-group variance, indicating no significant difference between groups."
      ],
      "metadata": {
        "id": "7CZkBm6m-yxU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ve0pBBoa-9F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
      ],
      "metadata": {
        "id": "SIkik3MoeTRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**               | **Classical (Frequentist) Approach**                                                                                      | **Bayesian Approach**                                                                                                                     |\n",
        "|--------------------------|--------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Uncertainty Handling**  | Handled through point estimates (e.g., sample means) and sampling distributions (e.g., confidence intervals).             | Handled through probability distributions (prior and posterior), reflecting the degree of belief about parameters.                        |\n",
        "| **Parameter Estimation**  | Parameters are estimated as fixed values (e.g., sample mean) using Maximum Likelihood Estimation (MLE).                    | Parameters are estimated as probability distributions (posterior) updated with observed data and prior beliefs.                           |\n",
        "| **Hypothesis Testing**    | Uses p-values to test null hypothesis, rejecting it if p-value is below a threshold (e.g., 0.05).                          | Uses Bayes factors or posterior probabilities to compare hypotheses without a strict null hypothesis.                                      |\n",
        "| **Interpretation of Results** | Results are based on the probability of observed data given the null hypothesis (p-value).                              | Results are based on the probability of a hypothesis given the data (posterior probability).                                              |\n",
        "| **Model Assumptions**    | Assumes a fixed model with constant parameters across experiments.                                                        | Assumes prior beliefs about parameters, which are updated with data to form posterior distributions.                                      |\n",
        "| **Flexibility in Hypotheses** | Rigid testing of pre-specified null and alternative hypotheses.                                                      | More flexible, allowing continuous updating of beliefs and comparison of multiple hypotheses.                                             |\n",
        "| **Focus on Estimation**   | Focus on obtaining point estimates and hypothesis testing.                                                              | Focus on updating beliefs and estimating distributions, considering uncertainty in all parameters.                                        |\n",
        "| **Reproducibility**       | Results are reproducible with the same data as the model is fixed.                                                        | Results can vary with different priors, but they converge as more data is gathered.                                                       |\n"
      ],
      "metadata": {
        "id": "uvbOPOO0fLyB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wcL96PMNe44f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Question: You have two sets of data representing the incomes of two different professions1\n",
        "# V Profession A: [48, 52, 55, 60, 62'\n",
        "# V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "# incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "# Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "# Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
      ],
      "metadata": {
        "id": "_Jo_SX1qfN9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for Profession A and Profession B\n",
        "profession_a = np.array([48, 52, 55, 60, 62])\n",
        "profession_b = np.array([45, 50, 55, 52, 47])\n",
        "\n",
        "# Calculate sample variances\n",
        "var_a = np.var(profession_a, ddof=1)  # sample variance for A\n",
        "var_b = np.var(profession_b, ddof=1)  # sample variance for B\n",
        "\n",
        "# Calculate the F-statistic (larger variance in numerator)\n",
        "F_statistic = max(var_a, var_b) / min(var_a, var_b)\n",
        "\n",
        "# Degrees of freedom for both samples\n",
        "df_a, df_b = len(profession_a) - 1, len(profession_b) - 1\n",
        "\n",
        "# Calculate the p-value for the F-distribution\n",
        "p_value = 2 * min(stats.f.cdf(F_statistic, df_a, df_b), 1 - stats.f.cdf(F_statistic, df_a, df_b))\n",
        "\n",
        "F_statistic, p_value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1HEOKMKfuDu",
        "outputId": "fed2f2a2-6300-4b74-c085-6ad3ea027944"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.089171974522293, 0.49304859900533904)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "- Since the p-value (0.493) is greater than the common significance level of 0.05, we fail to reject the null hypothesis.\n",
        "\n",
        "- The null hypothesis for this test states that the variances of the two professions' incomes are equal. Since the p-value is large, we do not have enough evidence to conclude that the variances of the incomes for Profession A and Profession B are significantly different.\n",
        "\n",
        "Final Conclusion:\n",
        "Based on the F-test, there is no significant difference in the variances of the two professions' incomes."
      ],
      "metadata": {
        "id": "cBIFwcPXiMQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XNrdwHXZgPZw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "# average heights between three different regions with the following data1\n",
        "# V Region A: [160, 162, 165, 158, 164'\n",
        "# V Region B: [172, 175, 170, 168, 174'\n",
        "# V Region C: [180, 182, 179, 185, 183'\n",
        "# V Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
        "# V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
      ],
      "metadata": {
        "id": "v4cCarYCiWns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for the three regions\n",
        "region_a = np.array([160, 162, 165, 158, 164])\n",
        "region_b = np.array([172, 175, 170, 168, 174])\n",
        "region_c = np.array([180, 182, 179, 185, 183])\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
        "\n",
        "# Display the results\n",
        "f_statistic, p_value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCHJqrRDissm",
        "outputId": "a24a12e4-75af-40f4-cc6e-8c6486920ca8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67.87330316742101, 2.870664187937026e-07)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "- Since the p-value is much smaller than 0.05, we reject the null hypothesis.\n",
        "- The null hypothesis states that all group means (average heights of the regions) are equal.\n",
        "\n",
        "- By rejecting the null hypothesis, we conclude that there are statistically significant differences in the average heights between the three regions.\n",
        "\n",
        "Final Interpretation:\n",
        "There is strong evidence to suggest that the average heights differ significantly between Region A, Region B, and Region C."
      ],
      "metadata": {
        "id": "b_9Zc9fMjGyO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4x79rfcQitcA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}